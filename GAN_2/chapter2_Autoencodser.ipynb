{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter2 오토인코더와 생성 학습\n",
    "- 이장에서 다음 내용을 다룹니다.\n",
    "- 잠재 공간으로 데이터를 인코더하고(차원 축소) 그다음 차원 확장하기\n",
    "- 변이형 오토인코더를 보면서 생성 모델링의 어려움을 이해한다.\n",
    "- 케라스와 오토 인코더를 이용한 손글씨 숫자 생성하기\n",
    "- 오토 인코더의 한계와 GAN의 필요성 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성 모델은 대부분 사람들에게 새로운 분야입니다.\n",
    "- 오토인코더는 GAN의 원조 격에 가장 가깝고 자료와 연구 결과가 풍부하다.\n",
    "### 생성 모델은 매우 도전적이다.\n",
    "- 오토인코더는 여러가지 면에서 흔히 배우는 모델(추후 다루게 될 명시적으로 목적 함수를 가진 모델)과 더 가깝지만 샘플의 품질을 평가하는 어려움 등 GAN이 마주하는 난점을 오터인코더에서도 발견할 수 있다.\n",
    "### 생성 모델은 오늘날 중요한 분야이다.\n",
    "- 오토인코더는 나름 용도가 있다. 오토인코더는 여전히 활발히 연구가 진행되는 분야이고 몇몇 분야에서 최첨단의 성과를 내며 많은 GAN구조에 사용되고있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 생성 모델링 시작하기\n",
    "- 생성하고 싶은 이미지를 먼저 계획한 다음 변환가정 끝에서 이미지를 얻는다. 이것이 가장 간단한 비정형 형태의 생성 모델링이다.\n",
    "- 특정한 계획 z가(0~9까지의 숫자)생성된 샘플인 $x^{*}$에 도달하려고 한다. 이상적으로 이 $x^{*}$은 실제 샘플인 x와 다를바 없어 보인다.\n",
    "- z는 잠재공간(latent space)에 위치하며 항상 같은 결과값 $x^{*}$을 얻지 않도록 도와준다. 잠재 공간은 학습된 표현방식이다. 즉 사람이 생각하는 방식과 비슷하다.\n",
    "- 다른 모델은 같은 데이터에서 다른 잠재표현(latent representation)을 학습할 것이다.\n",
    "\n",
    "- chapter 1 에 낳온 랜덤한 잡음 벡터는 잠재 공간에서 얻은 샘플이다.\n",
    "- 잠재 공간은 데이터 포인트를 더 간단하게 표현한 숨겨진 표현 방식이다. 즉, 저차원공간이다.\n",
    "- 데이터 포인트의 좋은 잠재 표현은 이 공간 속에서 유사한 것들끼리 묶는데 도움이 된다.\n",
    "- 오토인코더에서 잠재(latent)의 의미가 무엇인지 알아보자.\n",
    "- 그리고 생성된 샘플에 어떻게 영향을 미치는지 알아보자.\n",
    "\n",
    "## 2.2 오토인코더의 동작 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Dense,Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "original_dim = 784 # h*L\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "epochs = 50\n",
    "epsilon_std = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args: tuple):\n",
    "    z_mean,z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0.,stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2)*epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape = (original_dim,),name = \"input\")\n",
    "h = Dense(intermediate_dim, activation='relu', name = 'encoding')(x)\n",
    "z_mean = Dense(latent_dim,name=\"mean\")(h)\n",
    "z_log_var = Dense(latent_dim,name=\"log-variance\")(h)\n",
    "z = Lambda(sampling,output_shape = (latent_dim,))([z_mean,z_log_var])\n",
    "\n",
    "encoder = Model(x,[z_mean,z_log_var,z],name=\"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_decoder = Input(shape = (latent_dim,),name='decoder_input')\n",
    "decoder_h = Dense(intermediate_dim,activation = 'relu',name='decoder_h')(input_decoder)\n",
    "x_decoded = Dense(original_dim,activation='sigmoid',name=\"flat_decoded\")(decoder_h)\n",
    "decoder = Model(input_decoder,x_decoded,name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 784)]             0         \n",
      "                                                                 \n",
      " encoder (Functional)        [(None, 2),               201988    \n",
      "                              (None, 2),                         \n",
      "                              (None, 2)]                         \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 784)               202256    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 404,244\n",
      "Trainable params: 404,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_combined = decoder(encoder(x)[2])\n",
    "vae = Model(x,output_combined)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = -0.5*K.sum(\n",
    "    1+z_log_var-K.exp(z_log_var)-K.square(z_mean),\n",
    "    axis=-1\n",
    ")\n",
    "\n",
    "vae.add_loss(K.mean(kl_loss)/784.)\n",
    "vae.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "x_train = x_train.reshape((len(x_train),np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test),np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 18:12:40.602691: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-11 18:12:40.814342: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 7s 8ms/step - loss: 0.2454\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2188\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2136\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2102\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 0.2077\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2062\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2051\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2041\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2032\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2025\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2018\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2012\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2006\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.2001\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1996\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1991\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1987\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1982\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1979\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1974\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1970\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1967\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1963\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1960\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1957\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1954\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1952\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1949\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1947\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1944\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1942\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1940\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1938\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1936\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1934\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1932\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1931\n",
      "Epoch 38/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1929\n",
      "Epoch 39/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1928\n",
      "Epoch 40/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1926\n",
      "Epoch 41/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1925\n",
      "Epoch 42/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1923\n",
      "Epoch 43/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1921\n",
      "Epoch 44/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1921\n",
      "Epoch 45/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1919\n",
      "Epoch 46/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1917\n",
      "Epoch 47/50\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1916\n",
      "Epoch 48/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1915\n",
      "Epoch 49/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1914\n",
      "Epoch 50/50\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x281aa2a60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train,x_train,shuffle=\"True\",epochs=epochs,batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
